{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a26bd3-fcb7-43dd-aa23-6917e0438c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch scikit-learn pandas numpy matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c79947-c35a-4aef-a6ee-eea8195b7f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b00185-0a5d-4632-a8c7-4b6383b41d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "CSV_PATH = \"/home/psxkf4/IsaacLab/source/collected_data/offline_data_8192.csv\" \n",
    "\n",
    "# Set plot style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "# ==========================================\n",
    "# 2. LOAD DATA\n",
    "# ==========================================\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    print(f\"‚ùå Error: File not found at {CSV_PATH}\")\n",
    "    print(\"Please check the path and try again.\")\n",
    "else:\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "    print(f\"‚úÖ Successfully loaded data!\")\n",
    "    print(f\"   Rows (Envs): {df.shape[0]}\")\n",
    "    print(f\"   Columns:     {df.shape[1]}\")\n",
    "    \n",
    "    # Optional: Display the dataframe\n",
    "    # display(df)\n",
    "\n",
    "# --- FIX DATA TYPES ---\n",
    "# The 'gt_fric_force' column might be saved as strings (e.g., \"[4.23]\"). \n",
    "def clean_force_col(x):\n",
    "    if isinstance(x, str):\n",
    "        return float(x.strip('[]'))\n",
    "    return x\n",
    "\n",
    "if 'gt_fric_force' in df.columns:\n",
    "    df['gt_fric_force'] = df['gt_fric_force'].apply(clean_force_col)\n",
    "    print(\"‚úÖ Fixed 'gt_fric_force' column types.\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. HELPER FUNCTIONS\n",
    "# ==========================================\n",
    "def get_sequence_data(row, prefix, seq_len=100, num_axes=6):\n",
    "    \"\"\"Reconstructs (100, 6) array from flattened columns like 'prefix_t0_ax0'\"\"\"\n",
    "    data = np.zeros((seq_len, num_axes))\n",
    "    for t in range(seq_len):\n",
    "        for ax in range(num_axes):\n",
    "            col = f\"{prefix}_t{t}_ax{ax}\"\n",
    "            if col in row:\n",
    "                data[t, ax] = row[col]\n",
    "    return data\n",
    "\n",
    "def get_flat_window(row, prefix, window_size=10):\n",
    "    \"\"\"Reconstructs 1D array from columns like 'prefix_0', 'prefix_1'\"\"\"\n",
    "    data = np.zeros(window_size)\n",
    "    for i in range(window_size):\n",
    "        col = f\"{prefix}_{i}\"\n",
    "        if col in row:\n",
    "            data[i] = row[col]\n",
    "    return data\n",
    "\n",
    "# ==========================================\n",
    "# 4. DISTRIBUTION PLOTS (Targets)\n",
    "# ==========================================\n",
    "if 'df' in locals():\n",
    "    print(\"\\n--- Target Property Distributions ---\")\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # Mass\n",
    "    sns.histplot(df['gt_mass'], kde=True, ax=axes[0], color='tab:blue', bins=30)\n",
    "    axes[0].set_title('Ground Truth Mass Distribution')\n",
    "    axes[0].set_xlabel('Mass [kg]')\n",
    "    \n",
    "    # Friction Coeff\n",
    "    sns.histplot(df['gt_mu'], kde=True, ax=axes[1], color='tab:green', bins=30)\n",
    "    axes[1].set_title('Ground Truth Mu Distribution')\n",
    "    axes[1].set_xlabel('Friction Coefficient')\n",
    "    \n",
    "    # Friction Force\n",
    "    sns.histplot(df['gt_fric_force'], kde=True, ax=axes[2], color='tab:red', bins=30)\n",
    "    axes[2].set_title('Ground Truth Friction Force Distribution')\n",
    "    axes[2].set_xlabel('Friction Force [N]')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ==========================================\n",
    "# 5. INTEGRATED SAMPLE ANALYSIS (UPDATED WITH HIGHLIGHTS + MIN/MAX)\n",
    "# ==========================================\n",
    "if 'df' in locals():\n",
    "    # --- CONFIGURATION ---\n",
    "    AXIS_MOTION = 3   \n",
    "    AXIS_VERTICAL = 5 \n",
    "    G = 9.81\n",
    "\n",
    "    # 1. Pick a single random sample for ALL plots\n",
    "    sample_idx = np.random.randint(0, len(df))\n",
    "    row = df.iloc[sample_idx]\n",
    "    \n",
    "    print(f\"\\n=======================================================\")\n",
    "    print(f\"ANALYZING SAMPLE #{sample_idx}\")\n",
    "    print(f\"=======================================================\")\n",
    "    print(f\"GT Mass: {row['gt_mass']:.3f} kg\")\n",
    "    print(f\"GT Mu:   {row['gt_mu']:.3f}\")\n",
    "    \n",
    "    gt_fric_force_val = row['gt_fric_force']\n",
    "    if isinstance(gt_fric_force_val, str):\n",
    "        gt_fric_force_val = float(gt_fric_force_val.strip('[]'))\n",
    "    print(f\"GT Fric Force (Target): {gt_fric_force_val:.3f} N\")\n",
    "    print(f\"Time Window: {int(row['start_t'])} -> {int(row['end_t'])}\")\n",
    "\n",
    "    # --- HELPER TO ADD MIN/MAX TEXT ---\n",
    "    def add_min_max_text(ax, data, unit=\"\"):\n",
    "        dmin, dmax = np.min(data), np.max(data)\n",
    "        stats_text = f\"Min: {dmin:.3f} {unit}\\nMax: {dmax:.3f} {unit}\"\n",
    "        ax.text(0.95, 0.95, stats_text, transform=ax.transAxes, \n",
    "                horizontalalignment='right', verticalalignment='top', fontsize=12,\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='gray'))\n",
    "\n",
    "    # --- 2. EXTRACT DATA ---\n",
    "    raw_acc = get_sequence_data(row, \"raw_ee_acc\")\n",
    "    raw_vel = get_sequence_data(row, \"raw_ee_vel\")\n",
    "    \n",
    "    input_cols = [c for c in df.columns if \"input_acc_\" in c]\n",
    "    win_len = len(input_cols)\n",
    "    input_acc = get_flat_window(row, \"input_acc\", win_len)\n",
    "    input_vel = get_flat_window(row, \"input_vel\", win_len)\n",
    "    \n",
    "    lhs_wrench = get_sequence_data(row, \"pinn_LHS_wrench\")      \n",
    "    rhs_acc = get_sequence_data(row, \"pinn_RHS_acc\")            \n",
    "    robot_wrench = get_sequence_data(row, \"pinn_robot_wrench\")  \n",
    "    table_wrench = get_sequence_data(row, \"pinn_table_wrench\")  \n",
    "    \n",
    "    start_t = int(row['start_t'])\n",
    "    time_steps = np.arange(start_t, start_t + win_len)\n",
    "\n",
    "    # --- 3. CALCULATIONS ---\n",
    "    # Newton Check\n",
    "    net_force_sim = lhs_wrench[:, AXIS_MOTION]\n",
    "    acc_sim = rhs_acc[:, AXIS_MOTION]\n",
    "    net_force_calc = row['gt_mass'] * acc_sim\n",
    "\n",
    "    # Friction Check\n",
    "    robot_force_vertical = robot_wrench[:, AXIS_VERTICAL]\n",
    "    normal_force_calc = (row['gt_mass'] * G) - robot_force_vertical\n",
    "    fric_force_calc_profile = row['gt_mu'] * normal_force_calc\n",
    "    \n",
    "    normal_force_direct = table_wrench[:, AXIS_VERTICAL]\n",
    "    fric_force_direct_profile = row['gt_mu'] * normal_force_direct\n",
    "    \n",
    "    fric_force_gt_line = np.full_like(fric_force_calc_profile, gt_fric_force_val)\n",
    "\n",
    "    # --- 4. PLOTTING ---\n",
    "    fig, axes = plt.subplots(5, 1, figsize=(12, 18))\n",
    "    \n",
    "    # Plot 1: Velocity Input\n",
    "    axes[0].plot(raw_vel[:, AXIS_MOTION], label=f'Raw EE Vel (Axis {AXIS_MOTION})', color='gray', alpha=0.3)\n",
    "    axes[0].plot(time_steps, input_vel, 'b-o', linewidth=2, label='Extracted Input')\n",
    "    \n",
    "    axes[0].set_title(f\"1. Model Input: Velocity (Axis {AXIS_MOTION})\")\n",
    "    add_min_max_text(axes[0], input_vel, \"m/s\") # Add stats\n",
    "    axes[0].legend(loc='upper left')\n",
    "\n",
    "    # Plot 2: Acceleration Input\n",
    "    axes[1].plot(raw_acc[:, AXIS_MOTION], label=f'Raw EE Acc (Axis {AXIS_MOTION})', color='gray', alpha=0.3)\n",
    "    axes[1].plot(time_steps, input_acc, 'r-o', linewidth=2, label='Extracted Input')\n",
    "    \n",
    "    axes[1].set_title(f\"2. Model Input: Acceleration (Axis {AXIS_MOTION})\")\n",
    "    add_min_max_text(axes[1], input_acc, \"m/s^2\") # Add stats\n",
    "    axes[1].legend(loc='upper left')\n",
    "\n",
    "    # Plot 3: Component Breakdown\n",
    "    lhs_val = lhs_wrench[:, AXIS_MOTION]\n",
    "    robot_val = robot_wrench[:, AXIS_MOTION]\n",
    "    table_val = table_wrench[:, AXIS_MOTION]\n",
    "    \n",
    "    # Background\n",
    "    axes[2].plot(lhs_val, color='purple', linestyle='--', alpha=0.2)\n",
    "    axes[2].plot(robot_val, color='green', alpha=0.2)\n",
    "    axes[2].plot(table_val, color='orange', alpha=0.2)\n",
    "    \n",
    "    # Foreground\n",
    "    net_win = lhs_val[time_steps]\n",
    "    axes[2].plot(time_steps, net_win, label='LHS (Net Force)', color='purple', linestyle='--', linewidth=2)\n",
    "    axes[2].plot(time_steps, robot_val[time_steps], label='Robot Force', color='green', alpha=0.8, linewidth=2)\n",
    "    axes[2].plot(time_steps, table_val[time_steps], label='Table Force', color='orange', alpha=0.8, linewidth=2)\n",
    "    \n",
    "    axes[2].set_title(f\"3. Force Components Decomposition (Axis {AXIS_MOTION})\")\n",
    "    axes[2].set_ylabel(\"Force [N]\")\n",
    "    add_min_max_text(axes[2], net_win, \"N\") # Add stats for Net Force\n",
    "    axes[2].legend(loc='upper left')\n",
    "\n",
    "    # Plot 4: Newton's Law Check\n",
    "    # Background\n",
    "    axes[3].plot(net_force_sim, color='purple', linewidth=3, alpha=0.1)\n",
    "    axes[3].plot(net_force_calc, 'k--', linewidth=1.5, alpha=0.1)\n",
    "    \n",
    "    # Foreground\n",
    "    sim_win = net_force_sim[time_steps]\n",
    "    axes[3].plot(time_steps, sim_win, label='Simulated Net Force', color='purple', linewidth=3, alpha=0.5)\n",
    "    axes[3].plot(time_steps, net_force_calc[time_steps], 'k--', label='Calculated (GT Mass * Acc)', linewidth=1.5)\n",
    "    \n",
    "    axes[3].set_title(f\"4. Physics Check: Newton's 2nd Law (Axis {AXIS_MOTION})\")\n",
    "    axes[3].set_ylabel(\"Force [N]\")\n",
    "    add_min_max_text(axes[3], sim_win, \"N\") # Add stats for Sim Force\n",
    "    axes[3].legend(loc='upper left')\n",
    "\n",
    "    # Plot 5: Friction Model Check\n",
    "    # Background\n",
    "    axes[4].plot(fric_force_calc_profile, color='orange', alpha=0.2)\n",
    "    axes[4].plot(fric_force_direct_profile, color='green', linestyle=':', linewidth=2, alpha=0.2)\n",
    "    axes[4].plot(fric_force_gt_line, 'r--', linewidth=2, alpha=0.2)\n",
    "\n",
    "    # Foreground\n",
    "    calc_win = fric_force_calc_profile[time_steps]\n",
    "    axes[4].plot(time_steps, calc_win, label='Calculated Friction', color='orange', linewidth=2)\n",
    "    axes[4].plot(time_steps, fric_force_direct_profile[time_steps], label='Direct Friction', color='green', linestyle=':', linewidth=2)\n",
    "    axes[4].plot(time_steps, fric_force_gt_line[time_steps], 'r--', label=f'GT Target ({gt_fric_force_val:.2f} N)', linewidth=2)\n",
    "    \n",
    "    axes[4].set_title(f\"5. Physics Check: Friction Model (Normal Axis {AXIS_VERTICAL})\")\n",
    "    axes[4].set_ylabel(\"Force [N]\")\n",
    "    axes[4].set_xlabel(\"Time Step\")\n",
    "    add_min_max_text(axes[4], calc_win, \"N\") # Add stats for Calculated Friction\n",
    "    axes[4].legend(loc='upper left')\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b64af5-01dd-4eca-a309-1fdd000757e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ==========================================\n",
    "# 1. DATA PREPARATION & SHAPE CHECKS\n",
    "# ==========================================\n",
    "if 'df' in locals():\n",
    "    print(\"--- Preparing Data & Checking Shapes ---\")\n",
    "    \n",
    "    # 1. Identify Input Columns\n",
    "    acc_cols = [c for c in df.columns if \"input_acc_\" in c]\n",
    "    vel_cols = [c for c in df.columns if \"input_vel_\" in c]\n",
    "    \n",
    "    # Sort them numerically (input_acc_0, input_acc_1...)\n",
    "    acc_cols.sort(key=lambda x: int(x.split('_')[-1]))\n",
    "    vel_cols.sort(key=lambda x: int(x.split('_')[-1]))\n",
    "    \n",
    "    print(f\"Found {len(acc_cols)} Acceleration columns.\")\n",
    "    print(f\"Found {len(vel_cols)} Velocity columns.\")\n",
    "\n",
    "    # 2. Extract Flattened Data\n",
    "    X_acc_flat = df[acc_cols].values.astype(np.float32)\n",
    "    X_vel_flat = df[vel_cols].values.astype(np.float32)\n",
    "    \n",
    "    # --- FIX: Set Axes to 1 (Translational X only) ---\n",
    "    num_axes = 1  \n",
    "    \n",
    "    # Calculate Sequence Length\n",
    "    if len(acc_cols) % num_axes != 0:\n",
    "        print(\"‚ö†Ô∏è WARNING: Total columns not divisible by axis count!\")\n",
    "        \n",
    "    seq_len = len(acc_cols) // num_axes\n",
    "    print(f\"Detected Sequence Length: {seq_len} (Total Features: {len(acc_cols)})\")\n",
    "    \n",
    "    # Reshape to [Batch, Seq_Len, 1]\n",
    "    X_acc = X_acc_flat.reshape(-1, seq_len, num_axes)\n",
    "    X_vel = X_vel_flat.reshape(-1, seq_len, num_axes)\n",
    "    \n",
    "    print(f\"Reshaped Acc Tensor: {X_acc.shape} (Batch, Time, Axes)\")\n",
    "    print(f\"Reshaped Vel Tensor: {X_vel.shape} (Batch, Time, Axes)\")\n",
    "    \n",
    "    # 3. Extract Targets [Mass, Mu]\n",
    "    y = df[['gt_mass', 'gt_mu']].values.astype(np.float32)\n",
    "    print(f\"Targets Shape: {y.shape}\")\n",
    "    \n",
    "    # 4. Convert to PyTorch Tensors\n",
    "    X_acc_tensor = torch.tensor(X_acc)\n",
    "    X_vel_tensor = torch.tensor(X_vel)\n",
    "    y_tensor = torch.tensor(y)\n",
    "    \n",
    "    # 5. Train/Val Split\n",
    "    indices = np.arange(len(df))\n",
    "    train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_acc_tensor[train_idx], X_vel_tensor[train_idx], y_tensor[train_idx])\n",
    "    val_dataset = TensorDataset(X_acc_tensor[val_idx], X_vel_tensor[val_idx], y_tensor[val_idx])\n",
    "    \n",
    "    batch_size = 64\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Train Samples: {len(train_idx)} | Val Samples: {len(val_idx)}\")\n",
    "    print(\"‚úÖ Data preparation complete.\")\n",
    "else:\n",
    "    print(\"‚ùå Error: 'df' not found. Run Data Loading cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e73051-2914-4956-8c81-a04d13133c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    MATHEMATICAL LOGIC:\n",
    "    Since Transformers process sequences in parallel, they lack an inherent sense of time.\n",
    "    We inject a sinusoidal signal PE(pos, 2i) = sin(pos / 10000^(2i/d_model)) to encode \n",
    "    temporal order. This allows the model to distinguish between an acceleration spike \n",
    "    at t=65 versus steady-state motion at t=80.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, max_len=500):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        \n",
    "        # div_term defines the wavelength of the sinusoidal signals.\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Math: z_t = embedding_vector_t + PE_vector_t\n",
    "        return x + self.pe[:, :x.size(1), :]\n",
    "\n",
    "class PhysicsTransformerEstimator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=2,         # Subscript x_t: [vel, acc]\n",
    "        d_model=64,          # Latent dimension (d)\n",
    "        nhead=4,\n",
    "        # =========================================================================================\n",
    "        # MULTI-HEAD ATTENTION (nhead=4)\n",
    "        # =========================================================================================\n",
    "        # 1. SPLITTING: The d_model (64) is split into 4 heads of 16 dimensions each.\n",
    "        #    Math: head_dim = d_model // nhead = 16.\n",
    "        #\n",
    "        # 2. PARALLEL PHYSICS: Each head has its own W_Q, W_K, and W_V matrices.\n",
    "        #    This allows Head 1 to spotlight the 'Spike' while Head 2 spotlights the 'Slide'.\n",
    "        #\n",
    "        # 3. CONCATENATION: The 4 outputs [Batch, 20, 16] are glued together to form [Batch, 20, 64].\n",
    "        #    Final Context = Concat(head_1, head_2, head_3, head_4) @ W_O.\n",
    "        #\n",
    "        # 4. WHY 4?: It provides enough diversity to capture mass (transient) and \n",
    "        #    friction (steady-state) without making the feature space too small.\n",
    "        # =========================================================================================\n",
    "        num_encoder_layers=2, \n",
    "        dim_feedforward=128, \n",
    "        seq_len=20,          # T = 20\n",
    "        dropout=0.1          \n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        # ============================================================\n",
    "        # STEP 1: CONTINUOUS EMBEDDING & ENCODER\n",
    "        # Math: z_t = W_in * x_t + b_in\n",
    "        # W_in and b_in are TRAINABLE parameters. They learn how to \n",
    "        # map raw kinematics into a high-dimensional physical feature space.\n",
    "        # ============================================================\n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, max_len=seq_len + 10)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, \n",
    "            dim_feedforward=dim_feedforward, \n",
    "            batch_first=True, dropout=dropout\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "\n",
    "        # ============================================================\n",
    "        # STEP 2: DECODER (GENERATING h_t_dec)\n",
    "        # Math: h_t_dec = CrossAttention(q_t_query, H_enc, H_enc)\n",
    "        # h_t_dec is the hidden state for time step 't' that integrates \n",
    "        # the entire motion context into a force-ready representation.\n",
    "        # ============================================================\n",
    "        \n",
    "        # Parameter: Learned Time Queries\n",
    "        # Action: A trainable matrix representing \"what the model wants to know\" about each time step.\n",
    "        # MATH: In an LLM, Query = W_Q * Embedding. In your case, these ARE the Queries (Parameters).\n",
    "        # Instead of calculating them from the input, the model optimizes these 64D vectors \n",
    "        # during training to become \"templates\" for each of the 20 time steps.\n",
    "        # self.time_queries = nn.Parameter(torch.randn(1, seq_len, d_model) * 0.1)\n",
    "        self.time_queries = nn.Parameter(torch.randn(1, seq_len, d_model))\n",
    "        \n",
    "        # Layer: Cross-Attention\n",
    "        # Logic: The model performs the standard dot-product attention: \n",
    "        # Score = (q_dec * W_Q) @ (h_enc * W_K).T\n",
    "        # Even though q_dec starts as a fixed parameter, the 'MultiheadAttention' layer \n",
    "        # still applies a learned W_Q weight matrix to it during the forward pass.\n",
    "        self.cross_attn = nn.MultiheadAttention(d_model, nhead, batch_first=True, dropout=dropout)\n",
    "        \n",
    "        self.norm_dec = nn.LayerNorm(d_model)\n",
    "        self.ffn_dec = nn.Sequential(\n",
    "            nn.Linear(d_model, dim_feedforward), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(dim_feedforward, d_model)\n",
    "        )\n",
    "        self.norm_ffn = nn.LayerNorm(d_model)\n",
    "\n",
    "        # ============================================================\n",
    "        # STEP 3: INTERMEDIATE FORCE SEQUENCES\n",
    "        # Math: F_net_t = MLP_net(h_t_dec) and F_fric_t = MLP_fric(h_t_dec)\n",
    "        # These sequences decouple the transient (ma) from the steady (mu*m*g).\n",
    "        # ============================================================\n",
    "        self.net_force_mlp = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model), nn.ReLU(), nn.Linear(d_model, d_model)\n",
    "        ) \n",
    "        self.fric_force_mlp = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model), nn.ReLU(), nn.Linear(d_model, d_model)\n",
    "        ) \n",
    "\n",
    "        # ============================================================\n",
    "        # STEP 4: GLOBAL READOUTS (MASS & MU)\n",
    "        # We use Cross-Attention as a \"Spotlight\" to reduce sequences to scalars.\n",
    "        # Alpha_t^m: Weight assigned to frame t for mass calculation.\n",
    "        # ============================================================\n",
    "        \n",
    "        # --- A. MASS ESTIMATION ---\n",
    "        # Logic: q_mass learns to spotlight the acceleration peak (e.g., t=65).\n",
    "        \n",
    "        # Parameter: Mass Query (\"Spotlight\")\n",
    "        # MATH: Unlike an LLM where queries change per-word, self.q_mass is a GLOBAL Query.\n",
    "        # Think of it as a specialized \"sensor\" that is permanently tuned to the 64D \n",
    "        # frequency of a mass-impact event. It is optimized through backpropagation \n",
    "        # to have a high dot-product similarity with the 'feat_net' vectors at t=65.\n",
    "        # self.q_mass = nn.Parameter(torch.randn(1, 1, d_model) * 2.0)\n",
    "        # self.q_mass = nn.Parameter(torch.randn(1, 1, d_model))\n",
    "        self.mass_attn = nn.MultiheadAttention(d_model, 1, batch_first=True)\n",
    "        self.mass_pred_mlp = nn.Sequential(\n",
    "            nn.Linear(d_model, 64), nn.ReLU(), nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "        # --- B. FRICTION ESTIMATION ---\n",
    "        # Physics: F_fric = mu * m * g. \n",
    "        # Logic: We pass predicted Mass into the MLP so it can solve for mu = F / (m*g).\n",
    "\n",
    "        # Parameter: Friction Query\n",
    "        # MATH: Similarly, q_fric is a global learned parameter. It doesn't rely on \n",
    "        # input multiplication to exist; it is a dedicated query vector that has \n",
    "        # learned the \"look\" of steady-state latent friction features (t=75-83).\n",
    "        # self.q_fric = nn.Parameter(torch.randn(1, 1, d_model) * 2.0)\n",
    "        # self.q_fric = nn.Parameter(torch.randn(1, 1, d_model))\n",
    "        self.fric_attn = nn.MultiheadAttention(d_model, 1, batch_first=True)\n",
    "        self.mu_pred_mlp = nn.Sequential(\n",
    "            nn.Linear(d_model + 1, 64), nn.ReLU(), nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, extracted_acc, extracted_vel):\n",
    "        # x_t shape: [Batch, 20, 2]\n",
    "        x = torch.cat([extracted_vel, extracted_acc], dim=-1) \n",
    "        B, T, _ = x.shape\n",
    "\n",
    "        # ENCODER: Motion Context (h_enc)\n",
    "        # Every frame looks at every other frame to identify \"events\" (spikes/sliding).\n",
    "        # EXAMPLE: At t=65 (the deceleration spike), self-attention \"notices\" the sudden drop \n",
    "        # in velocity compared to t=50. It weights these frames highly to identify a \n",
    "        # \"Transient Event,\" which is the critical window for mass estimation.\n",
    "        # Conversely, at t=80, the model identifies \"Steady Sliding\" because acceleration \n",
    "        # remains near zero while velocity is constant.\n",
    "        \n",
    "        # Action: Project the 2D input [v, a] into a 64D Physical Feature Space.\n",
    "        # Once trained, W_in acts as a physical feature extractor. \n",
    "        # EXAMPLE: Just as \"King\" and \"Man\" are close in LLM embeddings, W_in maps \n",
    "        # (v=0.04, a=-3.5) to a \"Heavy Brake\" vector and (v=0.04, a=0.0) to a \n",
    "        # \"Steady Slide\" vector. These distinct regions in 64D space allow the \n",
    "        # Transformer to decouple inertial effects from surface friction.\n",
    "        z = self.input_proj(x)\n",
    "        z = self.pos_encoder(z)\n",
    "        h_enc = self.transformer_encoder(z)\n",
    "\n",
    "\n",
    "        # =========================================================================================\n",
    "        # 1. DECODER CROSS-ATTENTION: attn_output, _ = self.cross_attn(query=q_dec, key=h_enc, value=h_enc)\n",
    "        # =========================================================================================\n",
    "        # Even though we pass 'q_dec' and 'h_enc' directly, nn.MultiheadAttention \n",
    "        # INTERNALLY contains weight matrices W_Q, W_K, and W_V.\n",
    "        #\n",
    "        # Process per Attention Head (Head_i):\n",
    "        # A. Projection: \n",
    "        #    - Query (Q_i) = q_dec * W_i_Q (Your 20 learned time templates)\n",
    "        #    - Key (K_i) = h_enc * W_i_K (The 20 encoder context frames)\n",
    "        #    - Value (V_i) = h_enc * W_i_V (The actual features/information at those frames)\n",
    "        #\n",
    "        # B. Calculation:\n",
    "        #    - Score_Matrix = (Q_i @ K_i.T) / sqrt(d)\n",
    "        #    - This matrix is [20 queries x 20 keys], representing how much each query looks at each key.\n",
    "        #\n",
    "        # C. Output Generation:\n",
    "        #    - Head_Output = Softmax(Score_Matrix) @ V_i\n",
    "        #\n",
    "        # =========================================================================================\n",
    "        # 2. SOFTMAX LOGIC: ONE QUERY vs. ALL KEYS\n",
    "        # =========================================================================================\n",
    "        # Softmax is applied ROW-WISE (one query vs. all keys).\n",
    "        #\n",
    "        # Math: For a specific Query 't', AttentionWeight(t, j) = exp(Score_t_j) / sum_across_all_j(exp(Score_t_j)).\n",
    "        #\n",
    "        # Purpose:\n",
    "        # - It normalizes the dot-product multiplication (which can be any real number) into a \n",
    "        #   probability distribution.\n",
    "        # - For 'q_mass', this ensures the \"spotlight\" focuses on the acceleration spike at t=65 \n",
    "        #   by giving it a probability near 1.0, while quiet frames get near 0.0.\n",
    "        #\n",
    "        # =========================================================================================\n",
    "        # 3. WHY NOT JUST SOFTMAX(QK.T)?\n",
    "        # =========================================================================================\n",
    "        # We use Softmax( (QK.T) / sqrt(d) ) to stabilize gradients.\n",
    "        #\n",
    "        # Reason:\n",
    "        # - As the dimensionality 'd' increases, the magnitude of the dot product (Q @ K.T) grows large.\n",
    "        # - Large values push the Softmax function into regions where the gradient is extremely small.\n",
    "        # - Dividing by the scaling factor sqrt(d) keeps the values in a range where the model \n",
    "        #   can still learn effectively during training.\n",
    "        #\n",
    "        # =========================================================================================\n",
    "        # 4. VALUE MATRIX IN YOUR CASE: WHAT IS ADDED?\n",
    "        # =========================================================================================\n",
    "        # In the LLM \"fluffy creature\" example, 'fluffy' adds a \"texture\" signal to 'creature'.\n",
    "        #\n",
    "        # In your robotics case (Motion Context -> Force Sequence):\n",
    "        # - Query (q_dec_t): \"I am time slot t. What is the physical state here?\"\n",
    "        # - Key (h_enc_j): \"I am frame j, and I have a huge acceleration spike.\"\n",
    "        # - Value (v_j): Multiplication (h_enc_j * W_V).\n",
    "        #\n",
    "        # Conceptual Meaning of Value Multiplication:\n",
    "        # - If a frame is relevant (High Attention Score), the Value represents: \n",
    "        #   \"What specific force features should be written into this time slot?\"\n",
    "        # - For Sample 441, the Value at t=65 adds an \"11 Newton\" signal to the decoder state.\n",
    "        # - For Sample 2276, the Value at t=65 adds a \"9 Newton\" signal to the decoder state.\n",
    "        # - The model doesn't just pass the input; the Value matrix learns how to transform \n",
    "        #   kinematic history into force-generating features.\n",
    "        # =========================================================================================\n",
    "        q_dec = self.time_queries.expand(B, -1, -1)\n",
    "\n",
    "        # The layer internally applies W_Q to q_dec and W_K to h_enc here.\n",
    "        # attn_output, _ = self.cross_attn(query=q_dec, key=h_enc, value=h_enc)\n",
    "        attn_output, attn_weights = self.cross_attn(\n",
    "            query=q_dec, \n",
    "            key=h_enc, \n",
    "            value=h_enc, \n",
    "            average_attn_weights=False  # To visualize the individual attention patterns of the 4 heads within the cross_attn layer\n",
    "        )\n",
    "        h_dec = self.norm_dec(q_dec + attn_output)\n",
    "        h_dec = self.norm_ffn(h_dec + self.ffn_dec(h_dec))\n",
    "\n",
    "        # FORCE SEQUENCES: Decoupling Dynamics\n",
    "        # feat_net_t targets the Net Force Signal.\n",
    "        # feat_fric_t targets the Friction Signal.\n",
    "        feat_net = self.net_force_mlp(h_dec)\n",
    "        feat_fric = self.fric_force_mlp(h_dec)\n",
    "\n",
    "        # GLOBAL PROPERTY READOUT: Mass Prediction\n",
    "        # -------------------------------------------------------------------------\n",
    "        # MATH: Inside mass_attn, W_Q is applied to q_m_batch and W_K to feat_net.\n",
    "        # Query: \"Looking for inertial spikes.\"\n",
    "        # Key:   \"Answering with latent net-force signatures (e.g., the 11N peak).\"\n",
    "        # -------------------------------------------------------------------------\n",
    "        # q_m_batch = self.q_mass.expand(B, -1, -1)\n",
    "        # Instead of a fixed parameter, we find the \"strongest\" latent signal \n",
    "        # (the event peak) and use that to query the sequence.\n",
    "        q_m_dynamic, _ = torch.max(feat_net, dim=1, keepdim=True)\n",
    "        # mass_ctx, _ = self.mass_attn(query=q_m_batch, key=feat_net, value=feat_net)\n",
    "        mass_ctx, mass_weights = self.mass_attn(\n",
    "            query=q_m_dynamic * 2.0, \n",
    "            key=feat_net, \n",
    "            value=feat_net\n",
    "        )\n",
    "        mass_pred = self.mass_pred_mlp(mass_ctx.squeeze(1))\n",
    "\n",
    "        # GLOBAL PROPERTY READOUT: Friction Prediction\n",
    "        # -------------------------------------------------------------------------\n",
    "        # MATH: Inside fric_attn, W_Q is applied to q_f_batch and W_K to feat_fric.\n",
    "        # Query: \"Looking for steady-state sliding.\"\n",
    "        # Key:   \"Answering with latent friction-force signatures.\"\n",
    "        # -------------------------------------------------------------------------\n",
    "        # q_f_batch = self.q_fric.expand(B, -1, -1)\n",
    "        # Friction is often about the \"steady state\" rather than the peak.\n",
    "        # Mean-pooling provides a query for the \"average sliding\" state.\n",
    "        q_f_dynamic = torch.mean(feat_fric, dim=1, keepdim=True)\n",
    "        # fric_ctx, _ = self.fric_attn(query=q_f_batch, key=feat_fric, value=feat_fric)\n",
    "        fric_ctx, fric_weights = self.fric_attn(\n",
    "            query=q_f_dynamic * 2.0, \n",
    "            key=feat_fric, \n",
    "            value=feat_fric\n",
    "        )\n",
    "        \n",
    "        # Concatenate Mass for Physics Consistency\n",
    "        # Math: mu = f(Mass_Context, Mass_Scalar)\n",
    "        fric_input = torch.cat([fric_ctx.squeeze(1), mass_pred], dim=-1)\n",
    "        mu_pred = self.mu_pred_mlp(fric_input)\n",
    "\n",
    "        # Result: [Batch, 2] -> [Mass, Mu]\n",
    "        return torch.cat([mass_pred, mu_pred], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620c970f-d54e-4f4d-a51a-e11e07a4109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# # ==========================================\n",
    "# # INSPECT INITIALIZED VARIABLE SHAPES (FIXED)\n",
    "# # ==========================================\n",
    "\n",
    "# # 1. Instantiate the Model\n",
    "# model_inspect = PhysicsTransformerEstimator(\n",
    "#     input_dim=2,        # Velocity + Acceleration (1 axis each)\n",
    "#     d_model=64,         # Latent dimension\n",
    "#     nhead=4,            # Number of attention heads\n",
    "#     seq_len=20          # Sequence length\n",
    "# )\n",
    "\n",
    "# print(\"=\"*60)\n",
    "# print(\"PHYSICS TRANSFORMER: INITIALIZED VARIABLE SHAPES\")\n",
    "# print(\"=\"*60)\n",
    "\n",
    "# # --- A. SPECIAL LEARNABLE PARAMETERS (The \"Queries\") ---\n",
    "# print(\"\\n--- A. LEARNABLE QUERIES (The 'Spotlights') ---\")\n",
    "# # FIX: Wrap .shape in str() before formatting\n",
    "# print(f\"1. Time Queries (Decoder):   {str(model_inspect.time_queries.shape):<25} -> [1, Seq_Len, d_model]\")\n",
    "# print(f\"2. Mass Query (Readout):     {str(model_inspect.q_mass.shape):<25} -> [1, 1, d_model]\")\n",
    "# print(f\"3. Friction Query (Readout): {str(model_inspect.q_fric.shape):<25} -> [1, 1, d_model]\")\n",
    "\n",
    "# # --- B. ENCODER LAYERS ---\n",
    "# print(\"\\n--- B. ENCODER STRUCTURE ---\")\n",
    "# print(f\"Input Projection Weight:     {model_inspect.input_proj.weight.shape}\")\n",
    "# print(f\"Input Projection Bias:       {model_inspect.input_proj.bias.shape}\")\n",
    "# # Transformer Encoder (internal MHA weights)\n",
    "# enc_layer0 = model_inspect.transformer_encoder.layers[0]\n",
    "# print(f\"Encoder Layer 0 Self-Attn:   {enc_layer0.self_attn.in_proj_weight.shape} (Combined Q,K,V)\")\n",
    "\n",
    "# # --- C. DECODER LAYERS ---\n",
    "# print(\"\\n--- C. DECODER STRUCTURE ---\")\n",
    "# print(f\"Cross-Attn In-Proj Weight:   {model_inspect.cross_attn.in_proj_weight.shape} (Combined Q,K,V)\")\n",
    "# print(f\"Cross-Attn Out-Proj Weight:  {model_inspect.cross_attn.out_proj.weight.shape}\")\n",
    "# print(f\"Decoder FFN Linear 1:        {model_inspect.ffn_dec[0].weight.shape}\")\n",
    "# print(f\"Decoder FFN Linear 2:        {model_inspect.ffn_dec[2].weight.shape}\")\n",
    "\n",
    "# # --- D. LATENT FORCE HEADS ---\n",
    "# print(\"\\n--- D. LATENT FORCE HEADS ---\")\n",
    "# print(f\"Net Force MLP (Layer 1):     {model_inspect.net_force_mlp[0].weight.shape}\")\n",
    "# print(f\"Net Force MLP (Layer 2):     {model_inspect.net_force_mlp[2].weight.shape}\")\n",
    "# print(f\"Friction Force MLP (Layer 1):{model_inspect.fric_force_mlp[0].weight.shape}\")\n",
    "\n",
    "# # --- E. GLOBAL READOUT HEADS ---\n",
    "# print(\"\\n--- E. GLOBAL READOUT HEADS ---\")\n",
    "# # Mass Head\n",
    "# print(f\"Mass Attention Out-Proj:     {model_inspect.mass_attn.out_proj.weight.shape}\")\n",
    "# print(f\"Mass Prediction MLP (L1):    {model_inspect.mass_pred_mlp[0].weight.shape}\")\n",
    "# print(f\"Mass Prediction MLP (Out):   {model_inspect.mass_pred_mlp[2].weight.shape}\")\n",
    "\n",
    "# # Friction Head\n",
    "# print(f\"Friction Attn Out-Proj:      {model_inspect.fric_attn.out_proj.weight.shape}\")\n",
    "# print(f\"Mu Prediction MLP (L1):      {model_inspect.mu_pred_mlp[0].weight.shape} (Input = d_model + 1)\") \n",
    "# print(f\"Mu Prediction MLP (Out):     {model_inspect.mu_pred_mlp[2].weight.shape}\")\n",
    "\n",
    "# print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3391e67-f602-4f57-99f9-2c52e53cd1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# ==========================================\n",
    "# 2. MODEL SETUP & INIT\n",
    "# ==========================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using Device: {device}\")\n",
    "\n",
    "mse_loss = True\n",
    "log1p_mse_loss = False\n",
    "loss_type = \"data\" \n",
    "# loss_type = \"pinn\"\n",
    "\n",
    "# Initialize Model\n",
    "# input_dim=2 because we concatenate 1-axis Vel + 1-axis Acc\n",
    "model = PhysicsTransformerEstimator(\n",
    "    input_dim=2,          \n",
    "    d_model=64,           \n",
    "    nhead=4,              \n",
    "    num_encoder_layers=2, \n",
    "    seq_len=seq_len,      # Should be 20 based on your printout\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "# This prevents the larger mass values from overwhelming the \n",
    "# smaller friction coefficient gradients during training.\n",
    "def log_mse_loss(pred, target):\n",
    "    # Math: L = Mean( (log(1 + pred) - log(1 + target))^2 )\n",
    "    log_pred = torch.log1p(pred)\n",
    "    log_target = torch.log1p(target)\n",
    "    return F.mse_loss(log_pred, log_target)\n",
    "\n",
    "if mse_loss:\n",
    "    criterion = nn.MSELoss()\n",
    "    criterion_type = \"mse\"\n",
    "elif log1p_mse_loss:\n",
    "    criterion = log_mse_loss\n",
    "    criterion_type = \"log1p_mse\"\n",
    "    \n",
    "# Optimizer with Weight Decay (L2 Regularization) to prevent overfitting\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "# Scheduler to decay LR when validation loss plateaus\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min', \n",
    "    factor=0.5, \n",
    "    patience=20,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Model Initialized with input_dim=2 and seq_len={seq_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec45b3e1-5104-49d7-ba37-1038d6860289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# 3. TRAINING LOOP WITH LIVE PLOTTING & SAVING\n",
    "# ==========================================\n",
    "training = True\n",
    "\n",
    "num_epochs = 500\n",
    "train_losses, val_losses, lrs = [], [], []\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "printout_inter = 10\n",
    "plot_inter = 10  \n",
    "model_save_inter = 100\n",
    "\n",
    "# Directory setup\n",
    "checkpoint_dir = f\"checkpoints/{criterion_type}_{loss_type}\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "print(\"\\n--- Starting Training ---\")\n",
    "block_start_time = time.time()\n",
    "\n",
    "if training:\n",
    "    for epoch in range(num_epochs):\n",
    "        # --- TRAIN ---\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for b_acc, b_vel, b_y in train_loader:\n",
    "            b_acc, b_vel, b_y = b_acc.to(device), b_vel.to(device), b_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(b_acc, b_vel)\n",
    "            loss = criterion(output, b_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * b_acc.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_idx)\n",
    "        train_losses.append(epoch_loss)\n",
    "    \n",
    "        # --- VALIDATION ---\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for b_acc, b_vel, b_y in val_loader:\n",
    "                b_acc, b_vel, b_y = b_acc.to(device), b_vel.to(device), b_y.to(device)\n",
    "                output = model(b_acc, b_vel)\n",
    "                val_running_loss += criterion(output, b_y).item() * b_acc.size(0)\n",
    "                \n",
    "        epoch_val_loss = val_running_loss / len(val_idx)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        \n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        lrs.append(current_lr)\n",
    "        \n",
    "        # Update Scheduler\n",
    "        scheduler.step(epoch_val_loss)\n",
    "    \n",
    "        # --- BEST MODEL TRACKING ---\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            best_path = os.path.join(checkpoint_dir, \"best_model.pth\")\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "    \n",
    "        # --- LIVE PLOTTING BLOCK ---\n",
    "        if (epoch + 1) % plot_inter == 0:\n",
    "            clear_output(wait=True)\n",
    "            fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "            \n",
    "            # 1. Plot Losses\n",
    "            ax1.plot(train_losses, label='Train Loss', color='tab:blue', alpha=0.4)\n",
    "            ax1.plot(val_losses, label='Val Loss', color='tab:orange', linewidth=2)\n",
    "            # Add Horizontal line for the Best Loss seen so far\n",
    "            ax1.axhline(y=best_val_loss, color='green', linestyle=':', alpha=0.6, label=f'Best Val: {best_val_loss:.6f}')\n",
    "            \n",
    "            ax1.set_yscale('log')\n",
    "            ax1.set_xlabel('Epoch')\n",
    "            ax1.set_ylabel('Loss (Log Scale)', color='tab:blue')\n",
    "            ax1.legend(loc='upper left')\n",
    "            ax1.grid(True, which=\"both\", ls=\"-\", alpha=0.1)\n",
    "            \n",
    "            # 2. Plot Learning Rate\n",
    "            ax2 = ax1.twinx()\n",
    "            ax2.plot(lrs, label='LR', color='tab:red', linestyle='--')\n",
    "            ax2.set_yscale('log')\n",
    "            ax2.set_ylabel('Learning Rate', color='tab:red')\n",
    "            ax2.legend(loc='upper right')\n",
    "            \n",
    "            plt.title(f\"Live Training (Epoch {epoch+1}/{num_epochs})\")\n",
    "            plt.show()\n",
    "    \n",
    "        # --- LOGGING & SAVING ---\n",
    "        if (epoch + 1) % printout_inter == 0:\n",
    "            elapsed = time.time() - block_start_time\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}] | Train: {epoch_loss:.6f} | Val: {epoch_val_loss:.6f} | LR: {current_lr:.2e}\")\n",
    "            block_start_time = time.time()\n",
    "    \n",
    "        # Regular interval checkpointing\n",
    "        if (epoch + 1) % model_save_inter == 0:\n",
    "            save_path = os.path.join(checkpoint_dir, f\"transformer_epoch{epoch+1}.pth\")\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"    üíæ Regular Checkpoint saved: {save_path}\")\n",
    "\n",
    "    # ==========================================\n",
    "    # FINAL PLOT SAVE (After Loop)\n",
    "    # ==========================================\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "    ax1.plot(train_losses, label='Train Loss', color='tab:blue', alpha=0.4)\n",
    "    ax1.plot(val_losses, label='Val Loss', color='tab:orange', linewidth=2)\n",
    "    ax1.axhline(y=best_val_loss, color='green', linestyle=':', alpha=0.6, label=f'Best: {best_val_loss:.6f}')\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss', color='tab:blue')\n",
    "    ax1.legend(loc='upper left')\n",
    "    \n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(lrs, label='LR', color='tab:red', linestyle='--')\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.set_ylabel('Learning Rate', color='tab:red')\n",
    "    \n",
    "    plt.title(\"Final Training Dynamics - Success!\")\n",
    "    \n",
    "    # Save the file to your checkpoint directory\n",
    "    plot_save_path = os.path.join(checkpoint_dir, \"training_curves_final.png\")\n",
    "    plt.savefig(plot_save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"üìä Final training plot saved to: {plot_save_path}\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úÖ Training Complete. Best Val Loss: {best_val_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb9b7ee-1e24-4b8c-a62f-6814023c1266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# 4. LOAD CHECKPOINT & VISUALIZE\n",
    "# ==========================================\n",
    "\n",
    "# --- CONFIGURATION: WHICH MODEL TO LOAD? ---\n",
    "# Set this to the epoch number you want to load (e.g., 50000)\n",
    "# Or set to None to use the model currently in memory (if you just finished training)\n",
    "LOAD_EPOCH = 500\n",
    "CRITERION_TYPE = \"mse\"\n",
    "LOSS_TYPE = \"data\"\n",
    "CHECKPOINT_DIR = f\"checkpoints/{CRITERION_TYPE}_{LOSS_TYPE}\"\n",
    "\n",
    "# 1. Initialize Model Structure (Must match training config)\n",
    "#    (We re-initialize to ensure we are testing a clean state, or if running this later)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = PhysicsTransformerEstimator(\n",
    "    input_dim=2, \n",
    "    d_model=64, \n",
    "    nhead=4, \n",
    "    num_encoder_layers=2, \n",
    "    seq_len=20 # Make sure this matches your data prep\n",
    ").to(device)\n",
    "\n",
    "# 2. Load Weights\n",
    "if LOAD_EPOCH is not None:\n",
    "    # load_path = f\"{CHECKPOINT_DIR}/transformer_epoch{LOAD_EPOCH}.pth\"\n",
    "    load_path = f\"{CHECKPOINT_DIR}/best_model.pth\"\n",
    "    \n",
    "    if os.path.exists(load_path):\n",
    "        print(f\"üîÑ Loading model from: {load_path}\")\n",
    "        state_dict = torch.load(load_path, map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        print(\"‚úÖ Model weights loaded successfully!\")\n",
    "    else:\n",
    "        print(f\"‚ùå Error: Checkpoint not found at {load_path}\")\n",
    "        print(\"   Using random initialization or current model state.\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Using current model state (no file loaded).\")\n",
    "\n",
    "# 3. VISUALIZATION\n",
    "print(\"\\n--- Running Evaluation ---\")\n",
    "\n",
    "# A. Loss Curve (Only available if you just trained, otherwise skip)\n",
    "if 'train_losses' in locals() and len(train_losses) > 0:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Train Loss', linewidth=2)\n",
    "    plt.plot(val_losses, label='Validation Loss', linewidth=2)\n",
    "    plt.title(f'Training Curve (Loaded Epoch: {LOAD_EPOCH})')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è No training loss history found in memory (skipped plot).\")\n",
    "\n",
    "# B. Prediction Check (First 5 samples of Val Set)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Get a batch from validation loader\n",
    "    try:\n",
    "        sample_acc, sample_vel, sample_y = next(iter(val_loader))\n",
    "    except NameError:\n",
    "        print(\"‚ùå Error: 'val_loader' is not defined. Please run Data Preparation first.\")\n",
    "        sample_acc = None\n",
    "\n",
    "    if sample_acc is not None:\n",
    "        sample_acc, sample_vel = sample_acc.to(device), sample_vel.to(device)\n",
    "        preds = model(sample_acc, sample_vel).cpu()\n",
    "        \n",
    "        print(\"\\n--- Sample Predictions (Val Set) ---\")\n",
    "        print(f\"{'GT Mass':<10} {'Pred Mass':<10} | {'GT Mu':<10} {'Pred Mu':<10}\")\n",
    "        print(\"-\" * 45)\n",
    "        for i in range(5):\n",
    "            print(f\"{sample_y[i,0]:.4f}     {preds[i,0]:.4f}     | {sample_y[i,1]:.4f}     {preds[i,1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3676b7d1-d24f-49b7-828b-34949aa3d1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# ==========================================\n",
    "# MASTER EVALUATION CELL\n",
    "# ==========================================\n",
    "if 'model' in locals() and 'val_loader' in locals():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"STARTING COMPREHENSIVE PHYSICS-DRIVEN EVALUATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # PART 1: GLOBAL METRICS (Standard Estimation Accuracy)\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"1. Calculating Performance Metrics...\")\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for b_acc, b_vel, b_y in val_loader:\n",
    "            b_acc, b_vel = b_acc.to(device), b_vel.to(device)\n",
    "            preds = model(b_acc, b_vel)\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_targets.append(b_y.numpy())\n",
    "\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_targets = np.vstack(all_targets)\n",
    "\n",
    "    mass_gt, mass_pred = all_targets[:, 0], all_preds[:, 0]\n",
    "    mu_gt, mu_pred = all_targets[:, 1], all_preds[:, 1]\n",
    "\n",
    "    metrics = {\n",
    "        \"Mass MAE [kg]\": mean_absolute_error(mass_gt, mass_pred),\n",
    "        \"Mass R2\": r2_score(mass_gt, mass_pred),\n",
    "        \"Mu MAE\": mean_absolute_error(mu_gt, mu_pred),\n",
    "        \"Mu R2\": r2_score(mu_gt, mu_pred),\n",
    "    }\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k:<18}: {v:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # PART 2: STATISTICAL DASHBOARD (Estimation Quality)\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"2. Generating Statistical Dashboard...\")\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    fig1, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig1.suptitle(f\"Statistical Accuracy ($N={len(mass_gt)}$)\", fontsize=16)\n",
    "\n",
    "    # Parity Plots\n",
    "    sns.scatterplot(x=mass_gt, y=mass_pred, ax=axes[0,0], alpha=0.3, color='blue', s=10)\n",
    "    axes[0,0].plot([mass_gt.min(), mass_gt.max()], [mass_gt.min(), mass_gt.max()], 'r--')\n",
    "    axes[0,0].set_title(f\"Mass Parity (R¬≤={metrics['Mass R2']:.3f})\")\n",
    "    \n",
    "    sns.scatterplot(x=mu_gt, y=mu_pred, ax=axes[0,1], alpha=0.3, color='green', s=10)\n",
    "    axes[0,1].plot([mu_gt.min(), mu_gt.max()], [mu_gt.min(), mu_gt.max()], 'r--')\n",
    "    axes[0,1].set_title(f\"Friction Coeff Parity (R¬≤={metrics['Mu R2']:.3f})\")\n",
    "\n",
    "    # Residuals\n",
    "    sns.histplot(mass_pred - mass_gt, kde=True, ax=axes[1,0], color='blue', bins=50)\n",
    "    axes[1,0].set_title(\"Mass Prediction Residuals\")\n",
    "    axes[1,0].axvline(0, color='r', linestyle='--')\n",
    "    \n",
    "    sns.histplot(mu_pred - mu_gt, kde=True, ax=axes[1,1], color='green', bins=50)\n",
    "    axes[1,1].set_title(\"Mu Prediction Residuals\")\n",
    "    axes[1,1].axvline(0, color='r', linestyle='--')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # PART 3: PHYSICS RECONSTRUCTION (Newtonian Decoupling)\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"3. Visualizing Newtonian Decoupling (Sampled Force Profiles)...\")\n",
    "    num_samples = 2\n",
    "    indices = np.random.randint(0, len(df), size=num_samples)\n",
    "    AXIS_MOTION, AXIS_VERTICAL, G = 3, 5, 9.81\n",
    "    \n",
    "    fig2, axes2 = plt.subplots(num_samples, 2, figsize=(14, 4 * num_samples))\n",
    "    \n",
    "    acc_cols = [c for c in df.columns if \"input_acc_\" in c]\n",
    "    vel_cols = [c for c in df.columns if \"input_vel_\" in c]\n",
    "    acc_cols.sort(key=lambda x: int(x.split('_')[-1]))\n",
    "    vel_cols.sort(key=lambda x: int(x.split('_')[-1]))\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        row = df.iloc[idx]\n",
    "        x_acc_np = row[acc_cols].values.astype(np.float32).reshape(1, 20, 1)\n",
    "        x_vel_np = row[vel_cols].values.astype(np.float32).reshape(1, 20, 1)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds = model(torch.tensor(x_acc_np).to(device), torch.tensor(x_vel_np).to(device)).cpu().numpy()[0]\n",
    "        \n",
    "        rhs_acc = get_sequence_data(row, \"pinn_RHS_acc\")[int(row['start_t']):int(row['start_t'])+20]\n",
    "        rob_wrench = get_sequence_data(row, \"pinn_robot_wrench\")[int(row['start_t']):int(row['start_t'])+20]\n",
    "        time_steps = np.arange(20)\n",
    "\n",
    "        # Plot 1: The Mass Signature (Transient Net Force)\n",
    "        ax = axes2[i, 0]\n",
    "        ax.plot(time_steps, row['gt_mass'] * rhs_acc[:, AXIS_MOTION], 'b-', alpha=0.6, label='GT (Newton Check)')\n",
    "        ax.plot(time_steps, preds[0] * rhs_acc[:, AXIS_MOTION], 'r--', label=f'Pred (m={preds[0]:.2f})')\n",
    "        ax.set_title(f\"Newtonian Decoupling: Peak Net Force\")\n",
    "        ax.set_ylabel(\"Force [N]\")\n",
    "        ax.legend()\n",
    "        \n",
    "        # Plot 2: The Friction Signature (Steady-State Resistance)\n",
    "        ax = axes2[i, 1]\n",
    "        norm_force_gt = (row['gt_mass'] * G) - rob_wrench[:, AXIS_VERTICAL]\n",
    "        norm_force_pred = (preds[0] * G) - rob_wrench[:, AXIS_VERTICAL]\n",
    "        ax.plot(time_steps, row['gt_mu'] * norm_force_gt, 'g-', alpha=0.6, label='GT (Friction Check)')\n",
    "        ax.plot(time_steps, preds[1] * norm_force_pred, 'orange', linestyle='--', label=f'Pred (Œº={preds[1]:.2f})')\n",
    "        ax.set_title(f\"Friction Analysis: Constant Resistance\")\n",
    "        ax.set_ylabel(\"Force [N]\")\n",
    "        ax.legend()\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # PART 4: ATTENTION SPOTLIGHT ANALYSIS (Explainability)\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"4. Analyzing Attention Spotlights (The Transformer Spotlight)...\")\n",
    "    \n",
    "    activations = {}\n",
    "    def get_hook(name):\n",
    "        def hook(model, input, output):\n",
    "            if isinstance(output, tuple): activations[name] = output[1].detach().cpu()\n",
    "            else: activations[name] = output.detach().cpu()\n",
    "        return hook\n",
    "\n",
    "    hooks = [\n",
    "        model.mass_attn.register_forward_hook(get_hook('mass_attn')),\n",
    "        model.fric_attn.register_forward_hook(get_hook('fric_attn'))\n",
    "    ]\n",
    "\n",
    "    # Select random test sample\n",
    "    row = df.iloc[np.random.randint(0, len(df))]\n",
    "    x_acc = torch.tensor(row[acc_cols].values.astype(np.float32).reshape(1, 20, 1)).to(device)\n",
    "    x_vel = torch.tensor(row[vel_cols].values.astype(np.float32).reshape(1, 20, 1)).to(device)\n",
    "    \n",
    "    with torch.no_grad(): _ = model(x_acc, x_vel)\n",
    "    for h in hooks: h.remove()\n",
    "\n",
    "    fig3, ax_att = plt.subplots(figsize=(12, 5))\n",
    "    ax_att.set_title(f\"Transformer Explainability: Property Spotlights\", fontsize=14)\n",
    "    \n",
    "    # Scale kinematics for visibility\n",
    "    t = range(20)\n",
    "    acc_norm = row[acc_cols].values.astype(np.float32)\n",
    "    acc_norm = (acc_norm - acc_norm.min()) / (acc_norm.max() - acc_norm.min() + 1e-6)\n",
    "    \n",
    "    ax_att.plot(t, acc_norm, 'k:', alpha=0.4, label='Input Acceleration Shape')\n",
    "    \n",
    "    # Dual axis for Attention probabilities\n",
    "    ax_p = ax_att.twinx()\n",
    "    mass_weights = activations['mass_attn'].squeeze().numpy()\n",
    "    fric_weights = activations['fric_attn'].squeeze().numpy()\n",
    "    \n",
    "    ax_p.plot(t, mass_weights, 'blue', lw=3, label='Mass Attention (Transient)')\n",
    "    ax_p.fill_between(t, 0, mass_weights, color='blue', alpha=0.1)\n",
    "    \n",
    "    ax_p.plot(t, fric_weights, 'green', lw=3, label='Fric Attention (Steady-State)')\n",
    "    ax_p.fill_between(t, 0, fric_weights, color='green', alpha=0.1)\n",
    "    \n",
    "    ax_p.set_ylabel(\"Attention Score (Softmax Probability)\")\n",
    "    ax_att.set_xlabel(\"Time Step in Window\")\n",
    "    ax_att.legend(loc='upper left')\n",
    "    ax_p.legend(loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"‚úÖ COMPREHENSIVE PHYSICS EVALUATION COMPLETE.\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Model or Loader missing. Please run the training script.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508e68b0-0cd1-4fe8-a507-d1ae863153c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================\n",
    "# 4-HEAD CROSS-ATTENTION & SPOTLIGHT ANALYSIS\n",
    "# ============================================================\n",
    "model.eval()\n",
    "attn_maps = {}\n",
    "\n",
    "def get_attn_hook(name):\n",
    "    def hook(module, input, output):\n",
    "        # MultiheadAttention returns (output, weights)\n",
    "        if isinstance(output, tuple) and len(output) > 1:\n",
    "            attn_maps[name] = output[1].detach().cpu().numpy()\n",
    "    return hook\n",
    "\n",
    "# Register Hooks\n",
    "hooks = [\n",
    "    model.cross_attn.register_forward_hook(get_attn_hook('dec_enc')),  \n",
    "    model.mass_attn.register_forward_hook(get_attn_hook('mass_net')),  \n",
    "    model.fric_attn.register_forward_hook(get_attn_hook('fric_fric'))  \n",
    "]\n",
    "\n",
    "# Run Inference\n",
    "with torch.no_grad():\n",
    "    input_acc = x_acc.detach().clone().to(device) if torch.is_tensor(x_acc) else torch.from_numpy(x_acc).to(device)\n",
    "    input_vel = x_vel.detach().clone().to(device) if torch.is_tensor(x_vel) else torch.from_numpy(x_vel).to(device)\n",
    "    \n",
    "    # Ensure average_attn_weights=False is set in your model's forward pass \n",
    "    # to visualize all 4 heads separately.\n",
    "    _ = model(input_acc, input_vel)\n",
    "\n",
    "for h in hooks: h.remove()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# PLOTTING 4 HEADS + SPOTLIGHTS\n",
    "# ------------------------------------------------------------\n",
    "fig = plt.figure(figsize=(24, 25))\n",
    "gs = fig.add_gridspec(4, 4, hspace=0.4, wspace=0.3)\n",
    "\n",
    "t_steps = np.arange(20) # Time steps 0 ~ 19\n",
    "plot_vel = input_vel.detach().cpu().numpy().flatten()\n",
    "plot_acc = input_acc.detach().cpu().numpy().flatten()\n",
    "\n",
    "# Row 1: Kinematics with explicit t=0~19 labeling\n",
    "ax_v = fig.add_subplot(gs[0, :2])\n",
    "ax_v.plot(t_steps, plot_vel, 'g-o', label='EE Velocity')\n",
    "ax_v.set_title(\"Input: EE Velocity (v)\")\n",
    "ax_v.set_xticks(t_steps)\n",
    "ax_v.set_xlabel(\"Time Step (t)\")\n",
    "ax_v.set_ylabel(\"m/s\")\n",
    "ax_v.grid(True, alpha=0.3)\n",
    "\n",
    "ax_a = fig.add_subplot(gs[0, 2:])\n",
    "ax_a.plot(t_steps, plot_acc, 'b-s', label='EE Acceleration')\n",
    "ax_a.set_title(\"Input: EE Acceleration (a)\")\n",
    "ax_a.set_xticks(t_steps)\n",
    "ax_a.set_xlabel(\"Time Step (t)\")\n",
    "ax_a.set_ylabel(\"m/s¬≤\")\n",
    "ax_a.grid(True, alpha=0.3)\n",
    "\n",
    "# Row 2 & 3: The 4 Individual Heads of Cross-Attention\n",
    "cross_weights = attn_maps['dec_enc'][0] # Shape [4, 20, 20]\n",
    "\n",
    "for h_idx in range(4):\n",
    "    ax = fig.add_subplot(gs[1 if h_idx < 2 else 2, (h_idx % 2) * 2 : ((h_idx % 2) * 2) + 2])\n",
    "    # T is used to match Query as Column and Key as Row per your requirement\n",
    "    sns.heatmap(cross_weights[h_idx].T, ax=ax, cmap=\"magma\", cbar=True)\n",
    "    ax.set_title(f\"Cross-Attention Head {h_idx+1}\\n(Brighter = Higher Alignment)\")\n",
    "    ax.set_xlabel(\"Query (q_dec): Decoder Time Slot Search\")\n",
    "    ax.set_ylabel(\"Key (h_enc): Encoder Physical State\")\n",
    "\n",
    "# Row 4: Global Readout Spotlights (1 head each)\n",
    "# Mass Readout\n",
    "ax_m = fig.add_subplot(gs[3, :2])\n",
    "sns.heatmap(attn_maps['mass_net'][0].T, ax=ax_m, cmap=\"viridis\", annot=True, cbar=False)\n",
    "ax_m.set_title(\"Mass Readout (Single Expert Head)\\nTarget: Acceleration Spikes\")\n",
    "ax_m.set_xlabel(\"Query (q_m_batch): Mass Property Search\")\n",
    "ax_m.set_ylabel(\"Key (feat_net): Latent Force Sequence\")\n",
    "\n",
    "# Friction Readout\n",
    "ax_f = fig.add_subplot(gs[3, 2:])\n",
    "sns.heatmap(attn_maps['fric_fric'][0].T, ax=ax_f, cmap=\"viridis\", annot=True, cbar=False)\n",
    "ax_f.set_title(\"Friction Readout (Single Expert Head)\\nTarget: Steady Sliding\")\n",
    "ax_f.set_xlabel(\"Query (q_f_batch): Friction Property Search\")\n",
    "ax_f.set_ylabel(\"Key (feat_fric): Latent Friction Sequence\")\n",
    "\n",
    "plt.suptitle(\"Multi-Head Physics Analysis: Specialized Conversations\", fontsize=24, y=0.96)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dedc94-a4ad-4ebb-b5e3-e1f03c3fe962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================\n",
    "# 4-HEAD CROSS-ATTENTION & SPOTLIGHT WITH KINEMATIC EMPHASIS\n",
    "# ============================================================\n",
    "model.eval()\n",
    "attn_maps = {}\n",
    "\n",
    "def get_attn_hook(name):\n",
    "    def hook(module, input, output):\n",
    "        if isinstance(output, tuple) and len(output) > 1:\n",
    "            attn_maps[name] = output[1].detach().cpu().numpy()\n",
    "    return hook\n",
    "\n",
    "# Register Hooks\n",
    "hooks = [\n",
    "    model.cross_attn.register_forward_hook(get_attn_hook('dec_enc')),  \n",
    "    model.mass_attn.register_forward_hook(get_attn_hook('mass_net')),  \n",
    "    model.fric_attn.register_forward_hook(get_attn_hook('fric_fric'))  \n",
    "]\n",
    "\n",
    "# Run Inference\n",
    "with torch.no_grad():\n",
    "    input_acc = x_acc.detach().clone().to(device) if torch.is_tensor(x_acc) else torch.from_numpy(x_acc).to(device)\n",
    "    input_vel = x_vel.detach().clone().to(device) if torch.is_tensor(x_vel) else torch.from_numpy(x_vel).to(device)\n",
    "    _ = model(input_acc, input_vel)\n",
    "\n",
    "for h in hooks: h.remove()\n",
    "\n",
    "# Data Preparation\n",
    "t_steps = np.arange(20)\n",
    "plot_vel = input_vel.detach().cpu().numpy().flatten()\n",
    "plot_acc = input_acc.detach().cpu().numpy().flatten()\n",
    "\n",
    "def plot_emphasized_kinematics(ax, data, title, weights, color, ylabel):\n",
    "    \"\"\"Plots kinematics and emphasizes indices with max attention weights.\"\"\"\n",
    "    ax.plot(t_steps, data, color=color, marker='o', alpha=0.6, label=title)\n",
    "    # Find all indices with the maximum attention weight\n",
    "    max_val = np.max(weights)\n",
    "    max_indices = np.where(weights == max_val)[0]\n",
    "    \n",
    "    for idx in max_indices:\n",
    "        ax.axvspan(idx - 0.4, idx + 0.4, color='red', alpha=0.3, label='Max Attention' if idx == max_indices[0] else \"\")\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(t_steps)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.grid(True, alpha=0.2)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# PLOTTING GRID\n",
    "# ------------------------------------------------------------\n",
    "# Layout: 6 Rows (Head 1, Head 2, Head 3, Head 4, Mass, Friction)\n",
    "# Each row has: Velocity (Left), Acceleration (Center), Attention Map (Right)\n",
    "fig = plt.figure(figsize=(26, 35))\n",
    "gs = fig.add_gridspec(6, 3, hspace=0.5, wspace=0.3)\n",
    "\n",
    "# --- Rows 0 to 3: Cross-Attention Heads 1-4 ---\n",
    "cross_weights = attn_maps['dec_enc'][0] # Shape [4, 20, 20]\n",
    "for h_idx in range(4):\n",
    "    h_weights = cross_weights[h_idx]\n",
    "    # For emphasis, we take the mean weight across all decoder queries for that head\n",
    "    head_importance = np.mean(h_weights, axis=0) \n",
    "    \n",
    "    ax_v = fig.add_subplot(gs[h_idx, 0])\n",
    "    plot_emphasized_kinematics(ax_v, plot_vel, f\"Head {h_idx+1}: Velocity\", head_importance, 'green', \"m/s\")\n",
    "    \n",
    "    ax_a = fig.add_subplot(gs[h_idx, 1])\n",
    "    plot_emphasized_kinematics(ax_a, plot_acc, f\"Head {h_idx+1}: Acceleration\", head_importance, 'blue', \"m/s¬≤\")\n",
    "    \n",
    "    ax_m = fig.add_subplot(gs[h_idx, 2])\n",
    "    sns.heatmap(h_weights.T, ax=ax_m, cmap=\"magma\", cbar=True)\n",
    "    ax_m.set_title(f\"Head {h_idx+1} Alignment\\nQuery: q_dec | Key: h_enc\")\n",
    "\n",
    "# --- Row 4: Mass Readout ---\n",
    "mass_weights = attn_maps['mass_net'][0].flatten()\n",
    "ax_mv = fig.add_subplot(gs[4, 0])\n",
    "plot_emphasized_kinematics(ax_mv, plot_vel, \"Mass: Velocity Focus\", mass_weights, 'green', \"m/s\")\n",
    "ax_ma = fig.add_subplot(gs[4, 1])\n",
    "plot_emphasized_kinematics(ax_ma, plot_acc, \"Mass: Accel Focus\", mass_weights, 'blue', \"m/s¬≤\")\n",
    "ax_mm = fig.add_subplot(gs[4, 2])\n",
    "sns.heatmap(attn_maps['mass_net'][0].T, ax=ax_mm, cmap=\"viridis\", annot=True)\n",
    "ax_mm.set_title(\"Mass Spotlight\\nQuery: q_m_batch | Key: feat_net\")\n",
    "\n",
    "# --- Row 5: Friction Readout ---\n",
    "fric_weights = attn_maps['fric_fric'][0].flatten()\n",
    "ax_fv = fig.add_subplot(gs[5, 0])\n",
    "plot_emphasized_kinematics(ax_fv, plot_vel, \"Friction: Velocity Focus\", fric_weights, 'green', \"m/s\")\n",
    "ax_fa = fig.add_subplot(gs[5, 1])\n",
    "plot_emphasized_kinematics(ax_fa, plot_acc, \"Friction: Accel Focus\", fric_weights, 'blue', \"m/s¬≤\")\n",
    "ax_ff = fig.add_subplot(gs[5, 2])\n",
    "sns.heatmap(attn_maps['fric_fric'][0].T, ax=ax_ff, cmap=\"viridis\", annot=True)\n",
    "ax_ff.set_title(\"Friction Spotlight\\nQuery: q_f_batch | Key: feat_fric\")\n",
    "\n",
    "plt.suptitle(\"Specialized Attention Focus & Kinematic Emphasis\", fontsize=24, y=0.92)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18427f4b-7dce-4255-9607-c2a1995fa95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================\n",
    "# PHYSICS VS. LATENT RECONSTRUCTION COMPARISON\n",
    "# ============================================================\n",
    "model.eval()\n",
    "latent_data = {}\n",
    "\n",
    "def get_latent_hook(name):\n",
    "    def hook(module, input, output):\n",
    "        latent_data[name] = output.detach().cpu().numpy()\n",
    "    return hook\n",
    "\n",
    "# 1. Register hooks for latent force sequences\n",
    "hooks = [\n",
    "    model.net_force_mlp.register_forward_hook(get_latent_hook('feat_net')),\n",
    "    model.fric_force_mlp.register_forward_hook(get_latent_hook('feat_fric'))\n",
    "]\n",
    "\n",
    "# 2. Run inference on the current sample (using input_acc/input_vel from previous cell)\n",
    "with torch.no_grad():\n",
    "    _ = model(input_acc, input_vel)\n",
    "\n",
    "for h in hooks: h.remove()\n",
    "\n",
    "# 3. Calculate Ground Truth (GT) Forces from Dataframe\n",
    "# Assuming 'row' is the current sample being evaluated\n",
    "AXIS_MOTION, AXIS_VERTICAL, G = 3, 5, 9.81\n",
    "start_t = int(row['start_t'])\n",
    "end_t = start_t + 20\n",
    "\n",
    "# Get sequences for the 20-step window\n",
    "rhs_acc = get_sequence_data(row, \"pinn_RHS_acc\")[start_t:end_t]\n",
    "rob_wrench = get_sequence_data(row, \"pinn_robot_wrench\")[start_t:end_t]\n",
    "\n",
    "# Newtonian GT Calculation\n",
    "gt_net_force = row['gt_mass'] * rhs_acc[:, AXIS_MOTION]\n",
    "gt_normal_force = (row['gt_mass'] * G) - rob_wrench[:, AXIS_VERTICAL]\n",
    "gt_fric_force = row['gt_mu'] * gt_normal_force\n",
    "\n",
    "# 4. Normalize Latent Trends for visual comparison\n",
    "def norm_latent(arr): \n",
    "    res = np.mean(arr[0], axis=-1)\n",
    "    return (res - res.min()) / (res.max() - res.min() + 1e-6)\n",
    "\n",
    "net_latent_norm = norm_latent(latent_data['feat_net'])\n",
    "fric_latent_norm = norm_latent(latent_data['feat_fric'])\n",
    "t_steps = np.arange(20)\n",
    "\n",
    "# 5. Plotting Comparison\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 12))\n",
    "\n",
    "# --- Plot 1: Net Force (ma) Comparison ---\n",
    "ax1_twin = axes[0].twinx()\n",
    "lns1 = axes[0].plot(t_steps, gt_net_force, 'b-', alpha=0.6, label='GT Net Force (ma) [N]')\n",
    "lns2 = ax1_twin.plot(t_steps, net_latent_norm, 'r--', lw=2, label='Latent Activation (feat_net)')\n",
    "axes[0].set_title(f\"Net Force Decoupling Check (Sample {idx})\")\n",
    "axes[0].set_ylabel(\"Physical Force [N]\", color='blue')\n",
    "ax1_twin.set_ylabel(\"Latent Magnitude (Normalized)\", color='red')\n",
    "\n",
    "# --- Plot 2: Friction (mu*N) Comparison ---\n",
    "ax2_twin = axes[1].twinx()\n",
    "lns3 = axes[1].plot(t_steps, gt_fric_force, 'g-', alpha=0.6, label='GT Friction (mu*N) [N]')\n",
    "lns4 = ax2_twin.plot(t_steps, fric_latent_norm, 'orange', linestyle='--', lw=2, label='Latent Activation (feat_fric)')\n",
    "axes[1].set_title(\"Friction Decoupling Check\")\n",
    "axes[1].set_ylabel(\"Physical Force [N]\", color='green')\n",
    "ax2_twin.set_ylabel(\"Latent Magnitude (Normalized)\", color='orange')\n",
    "\n",
    "# Combine legends\n",
    "all_lns1 = lns1 + lns2\n",
    "labs1 = [l.get_label() for l in all_lns1]\n",
    "axes[0].legend(all_lns1, labs1, loc='upper right')\n",
    "\n",
    "all_lns2 = lns3 + lns4\n",
    "labs2 = [l.get_label() for l in all_lns2]\n",
    "axes[1].legend(all_lns2, labs2, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c386eb58-fd3c-4147-a93f-7f7de897d383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f135022b-1c5a-47d4-9ff8-da8f01fa332b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319af1cc-4314-4db3-8439-4f8445f9173b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
